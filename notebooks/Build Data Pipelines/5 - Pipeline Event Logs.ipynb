{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae76439-554a-4cf4-ad1c-85a45226148b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b19c20f8-eb48-4365-8f4c-d91416145625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exploring the Pipeline Events Logs\n",
    "\n",
    "DLT uses the event logs to store much of the important information used to manage, report, and understand what's happening during pipeline execution.\n",
    "\n",
    "DLT stores log information in a special table called the `event_log`. To access log data from this table, you must use the **`event_log`** table valued function (TVF). We will use this function in the cells that follow, passing the  pipeline id as a parameter.\n",
    "\n",
    "Below, we provide a number of useful queries to explore the event log and gain greater insight into your DLT pipelines.\n",
    "\n",
    "Run the setup script below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6045ce19-c673-41be-862b-dd5edd38dd8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-04.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b1b7d27-3201-436d-a9c7-d03e29616321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Required Query\n",
    "Run the next cell to generate a query we will need a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb0b917d-2818-4870-bc17-621e6d7a318c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "DA.print_catalog_and_pipeline_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcaf4d7b-8261-4a7d-9fb0-5e1acb9fce85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Important -- Please Read!\n",
    "The rest of the cells in this notebook must be run with either a cluster that is in **shared** access mode or with a SQL warehouse.\n",
    "\n",
    "**We will be using a SQL warehouse.**\n",
    "\n",
    "Please click the cluster name at the top of the page and switch to a SQL warehouse.\n",
    "\n",
    "SQL warehouses provide instant, elastic SQL compute — decoupled from storage — and will automatically scale to provide unlimited concurrency without disruption, for high concurrency use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83a32373-dd31-4061-a857-d52abe567fbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Query Event Log\n",
    "The event log is managed as a Delta Lake table with some of the more important fields stored as nested JSON data.\n",
    "\n",
    "Copy the query from the previous code cell's output into the next cell, and run the code. This query shows how simple it is to read the event log table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "971f4eb9-bdea-4d9c-9051-25ec0c0a4f0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Copy the query from the previous code cell's output into this cell.\n",
    "-- This cell must be run on a shared cluster or SQL warehouse.\n",
    "\n",
    "<REPLACE WITH THE OUTPUT FROM THE PREVIOUS CODE CELL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1646e31-56b4-4333-abca-0eca4cac71f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The query in the previous cell uses the [**`event_log`** table-valued function](https://docs.databricks.com/en/sql/language-manual/functions/event_log.html). This is a built in function that allows you to query the event log for materialized views, streaming tables, and DLT pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fc0cb8c-7290-4482-b73a-04b8be9256f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Perform Audit Logging\n",
    "\n",
    "Events related to running pipelines and editing configurations are captured as **`user_action`**.\n",
    "\n",
    "Yours should be the only **`user_name`** for the pipeline you configured during this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd5e0c1b-35d1-408c-aa52-44ceb37b0405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT timestamp, details:user_action:action, details:user_action:user_name\n",
    "  FROM pipeline_event_log\n",
    "  WHERE event_type = 'user_action'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "516d57a7-6086-4338-b7d7-03a63011c991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get Latest Update ID\n",
    "\n",
    "In many cases, you may wish to get information about the latest update to your pipeline.\n",
    "\n",
    "We can easily capture the most recent update ID with a SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20fe3a20-7c51-4681-89f3-8fbf3e0d9d82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECLARE OR REPLACE VARIABLE latest_update_id STRING;\n",
    "SET VARIABLE latest_update_id =\n",
    "(SELECT origin.update_id\n",
    "    FROM pipeline_event_log\n",
    "    WHERE event_type = 'create_update'\n",
    "    ORDER BY timestamp DESC LIMIT 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cca2ea63-e1c3-42af-aad5-b063a8d0408c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Examine Lineage\n",
    "\n",
    "DLT provides built-in lineage information for how data flows through your table.\n",
    "\n",
    "While the query below only indicates the direct predecessors for each table, this information can easily be combined to trace data in any table back to the point it entered the lakehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f846f085-f8f7-4778-bff2-81f7f1e8937a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT details:flow_definition.output_dataset, details:flow_definition.input_datasets \n",
    "  FROM pipeline_event_log\n",
    "WHERE event_type = 'flow_definition' AND \n",
    "      origin.update_id = latest_update_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebcdb922-d54c-4ebb-b944-2829a5a68ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Examine Data Quality Metrics\n",
    "\n",
    "Finally, data quality metrics can be extremely useful for both long term and short term insights into your data.\n",
    "\n",
    "Below, we capture the metrics for each constraint throughout the entire lifetime of our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd68ee2-8119-4956-9fd6-8229d7bb1e5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT row_expectations.dataset as dataset,\n",
    "       row_expectations.name as expectation,\n",
    "       SUM(row_expectations.passed_records) as passing_records,\n",
    "       SUM(row_expectations.failed_records) as failing_records\n",
    "FROM\n",
    "  (SELECT explode(\n",
    "            from_json(details :flow_progress :data_quality :expectations,\n",
    "                      \"array<struct<name: string, dataset: string, passed_records: int, failed_records: int>>\")\n",
    "          ) row_expectations\n",
    "   FROM pipeline_event_log\n",
    "   WHERE event_type = 'flow_progress' AND \n",
    "         origin.update_id = latest_update_id\n",
    "  )\n",
    "GROUP BY row_expectations.dataset, row_expectations.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ada3875-963f-4e48-aedb-fa01441ef156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2024 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the \n",
    "<a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5 - Pipeline Event Logs",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}