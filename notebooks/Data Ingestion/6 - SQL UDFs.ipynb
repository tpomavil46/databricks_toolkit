{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41eb3b75-caeb-4c8c-bde3-9c356904faaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ca289e8-2b12-4e0e-8ba7-9e3eedfa4369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# SQL UDFs\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you should be able to:\n",
    "* Define and registering SQL UDFs\n",
    "* Describe the security model used for sharing SQL UDFs\n",
    "* Use **`CASE`** / **`WHEN`** statements in SQL code\n",
    "* Leverage **`CASE`** / **`WHEN`** statements in SQL UDFs for custom control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d4e246a-0d62-450d-9d4f-ee94eaee7bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "## Run Setup\n",
    "Run the following cell to setup your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f476af8e-fedf-4f22-93af-ad6949e4344c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-02.7A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b62b950-13c9-4820-8aaf-18b48462d4f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## User-Defined Functions\n",
    "\n",
    "User Defined Functions (UDFs) in Spark SQL allow you to register custom SQL logic as functions in a database, making these methods reusable anywhere SQL can be run on Databricks. These functions are registered natively in SQL and maintain all of the optimizations of Spark when applying custom logic to large datasets.\n",
    "\n",
    "At minimum, creating a SQL UDF requires a function name, optional parameters, the type to be returned, and some custom logic.\n",
    "\n",
    "Below, a simple function named **`sale_announcement`** takes an **`item_name`** and **`item_price`** as parameters. It returns a string that announces a sale for an item at 80% of its original price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b43b301b-acab-41fc-abb2-2b02d7d32483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION sale_announcement(item_name STRING, item_price INT)\n",
    "RETURNS STRING\n",
    "RETURN concat(\"The \", item_name, \" is on sale for $\", round(item_price * 0.8, 0));\n",
    "\n",
    "SELECT *, sale_announcement(name, price) AS message FROM item_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e9b1b97-af27-4a06-919a-b1f65701aa8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that this function is applied to all values of the column in a parallel fashion within the Spark processing engine. SQL UDFs are an efficient way to define custom logic that is optimized for execution on Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dff5537-7968-4482-a52b-4a10e25aed63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Scoping and Permissions of SQL UDFs\n",
    "SQL user-defined functions:\n",
    "- Persist between execution environments (which can include notebooks, DBSQL queries, and jobs).\n",
    "- Exist as objects in the metastore and are governed by the same Table ACLs as databases, tables, or views.\n",
    "- To **create** a SQL UDF, you need **`USE CATALOG`** on the catalog, and **`USE SCHEMA`** and **`CREATE FUNCTION`** on the schema.\n",
    "- To **use** a SQL UDF, you need **`USE CATALOG`** on the catalog, **`USE SCHEMA`** on the schema, and **`EXECUTE`** on the function.\n",
    "\n",
    "We can use **`DESCRIBE FUNCTION`** to see where a function was registered and basic information about expected inputs and what is returned (and even more information with **`DESCRIBE FUNCTION EXTENDED`**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca3b80df-a4d1-4c53-9e51-0bcc99022e61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE FUNCTION EXTENDED sale_announcement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e89816b-37cb-4fc1-9e89-f458b9bb3a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that the **`Body`** field at the bottom of the function description shows the SQL logic used in the function itself.\n",
    "## Viewing Functions in the Catalog Explorer\n",
    "After we create a function, it is associated with a schema. We can view the functions associated with a schema in the Catalog Explorer. \n",
    "1. Click **Catalog** in the left navigation bar.\n",
    "1. Paste your catalog name in the cell marked \"Type to filter.\" Note: Run the next cell to get the name of your current catalog.\n",
    "1. Drill into the catalog name to reveal the list of schemas in your catalog by clicking the disclosure triangle to the left of the catalog name.\n",
    "1. Drill open the schema name, \"default.\" Note, that there are two functions associated with the schema: **`item_preference`** and **`sale_announcement`**.\n",
    "1. Click **`item_preference`** and explore information about the function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afdb83c7-7424-40e6-8848-f2247ae238e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39096302-df02-4932-9148-b36dd76505c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simple Control Flow Functions\n",
    "\n",
    "Combining SQL UDFs with control flow in the form of **`CASE`** / **`WHEN`** clauses provides optimized execution for control flows within SQL workloads. The standard SQL syntactic construct **`CASE`** / **`WHEN`** allows the evaluation of multiple conditional statements with alternative outcomes based on table contents.\n",
    "\n",
    "Here, we demonstrate wrapping this control flow logic in a function that will be reusable anywhere we can execute SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "691dcc3f-e8b0-40fe-ae3c-6370c39a5b52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION item_preference(name STRING, price INT)\n",
    "RETURNS STRING\n",
    "RETURN CASE \n",
    "  WHEN name = \"Standard Queen Mattress\" THEN \"This is my default mattress\"\n",
    "  WHEN name = \"Premium Queen Mattress\" THEN \"This is my favorite mattress\"\n",
    "  WHEN price > 100 THEN concat(\"I'd wait until the \", name, \" is on sale for $\", round(price * 0.8, 0))\n",
    "  ELSE concat(\"I don't need a \", name)\n",
    "END;\n",
    "\n",
    "SELECT *, item_preference(name, price) FROM item_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8832d53a-c15c-432f-ae50-d4be2bf8a01a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While the examples provided here are simple, these same basic principles can be used to add custom computations and logic for native execution in Spark SQL. \n",
    "\n",
    "Especially for enterprises that might be migrating users from systems with many defined procedures or custom-defined formulas, SQL UDFs can allow a handful of users to define the complex logic needed for common reporting and analytic queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f041e1f-3926-4f5b-b3e8-2eb0e3532553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the following cell to delete the tables and files associated with this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b824292-0e02-4671-ba18-af6e53708314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "377c6194-dc85-4b5d-b537-c3e816542bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2024 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the \n",
    "<a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "6 - SQL UDFs",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}